% TODO: All conclusions have slightly changed due to the changed research questions
\section{Conclusion} \label{sec:conclusion}
This conclusion will give an answer to the main question of this literature study: \airquote{\textit{What is a suitable method to perform traffic scene \gls{OGM} prediction using Deep Learning in current literature?}} 
To answer this question, an investigation has been done on current, state-of-the-art, literature to find the most suitable \gls{OGM} form, dataset, metric, and deep learning method, by answering the following four sub-questions. 

\begin{enumerate}
	\item \textit{What \gls{OGM} form is suitable to use in \gls{OGM} prediction methods?}
	\item \textit{What is a suitable dataset to generate \gls{OGM} sequences for \gls{OGM} prediction from among current traffic scene datasets?}
	\item \textit{What is a suitable quantitative metric to determine the accuracy of a predicted \gls{OGM} among the metrics used in current \gls{OGM} prediction literature?}
	\item \textit{What is an accurate Deep Learning method to generate \gls{OGM} predictions in current literature?}	
\end{enumerate}

The answers to the sub-questions, that together answer the main question are as follows. First, the suitable \gls{OGM} to use in prediction methods is the \gls{DST} generated \gls{OGM}. Whether a specific \gls{OGM} extension should be used depends on the goal for the prediction. Generally, the more extensions, the more accurate the predictions, but the more computation power is required to train and execute the prediction network. Second, the suitable datasets to generate \gls{OGM} sequences for \gls{OGM} prediction are the Waymo \cite{sun2020scalability} dataset for generating \glspl{OGM} without extensions, the Cityscapes \cite{cordts2016cityscapes} dataset for generating \glspl{OGM} with semantic segmentation on pixel level, and the Nuscenes \cite{caesar2020nuscenes} dataset to generate \glspl{DOGMa} using radar velocity data and to add semantic segmentation on pixel level. Third, a suitable quantitative metric to determine the accuracy of a predicted \gls{OGM} is either the \gls{SSIM} or the \gls{IS} metric. Fourth, the deep learning method that generates accurate \gls{OGM} predictions cannot be determined yet. The investigated methods cannot be compared well, because they are either trained on different datasets or evaluated using different, not all suitable, metrics. 


\section{Future Work} \label{sec:future}
Based on the conclusion of this literature study, some ideas for future research are proposed in this section. The proposals below are categorized into four categories: Datasets, Metrics, Loss functions, and Methods. Subsequently, chapter \ref{sec:res_prop} proposes a Master thesis research which elaborates on the Loss Functions future work.

\paragraph{Datasets}
This literature review gave an extensive overview of the plethora of datasets that contain traffic scene information from an ego-vehicle point of view. However, most datasets were not recorded with the purpose to use them for \gls{OGM} generation and (motion) prediction. Therefore, not all datasets have been used before for these purposes, given the found literature. Based on the set criteria for the datasets, if there was literature that showed that a dataset has previously been used to generate or predict \gls{OGM}, its score increased. Intuitively, it is probable that the motion prediction datasets are more likely to be used for \gls{OGM} generation and prediction compared to the other datasets. Therefore, those datasets are more likely to score higher based on the set criteria. To even out the dataset's playing field, future research could be done by investigating whether \glspl{OGM} can be generated and predicted for each dataset. Then, the focus could lie more on the other criteria. 
Furthermore, the datasets are evaluated according to criteria that were set based on literature about dataset quality and based on practical reasons. Perhaps, given some other criteria, the datasets would have scored differently. Therefore, this review proposes a research that investigates the quality of traffic scene datasets used for \gls{OGM} generation and prediction. To evaluate the datasets, more extensive research could be done to set up adequate criteria that a dataset should meet. \\

\paragraph{Metrics}
The evaluated metrics in this literature review were metrics that were previously used in papers about \gls{OGM} prediction. This review concluded that, based on the set criteria, the suitable metrics to evaluate \glspl{OGM} are the \gls{SSIM} and \gls{IS} metrics. To determine which of the two metrics is better, research could be done that compares the metrics against other criteria. For example, the criteria in this literature study were based on ensuring traffic safety. To test traffic safety, an investigation in a traffic simulation could be done to evaluate the behavior of an \gls{AV} and its surroundings, given different \gls{OGM} predictions. The metric that best correlates its score of the \gls{OGM} predictions with the resulting traffic safety would be the best metric. 
Furthermore, \glspl{OGM} have a similar structure to images. Therefore, there might be other metrics, originally used for image comparison, that could be more suitable to assess \glspl{OGM} compared to the ones in this literature study. Research should be done to find more metrics and compare those to the metrics assessed in this review. 

\paragraph{Loss Functions}
Chapter \ref{subsec:lossfunc} assesses the various loss functions that were used to train the different \gls{OGM} prediction methods. When evaluating the loss functions against the criteria that were set for the metrics, it is found that only one loss function meets all criteria. This loss function is the \gls{SSIM}. The reason why it meets all set criteria is because it considers grid cell dependencies compared to the other loss functions which only assess each grid cell independently. According to the metrics criteria, the former would provide a better assessment of the network's output compared to the latter. This raises the question whether the use of a loss function that considers grid cell dependencies, such as the \gls{SSIM}, improves how a network is trained compared to using a loss function which evaluates each grid cell independently. Therefore, future work is proposed that compares the effect of loss functions that consider independent grid cells with loss functions that consider a dependency between grid cells. 

\paragraph{Methods}
In this literature study, only \gls{OGM} prediction methods are evaluated. However, there are other methods found in literature that use \glspl{OGM} as input but only predict the future states of the traffic participants within the \gls{OGM} instead of predicting the complete future \glspl{OGM}. Two examples of state prediction methods using \gls{OGM} sequences as input are given as follows.
A recent state-of-the-art method by Li \cite{li2020end} proposes an end-to-end Transformer network that performs object detection and trajectory prediction of an \gls{AV}'s environment using its raw LiDAR and camera data as input in the form of 3D \glspl{OGM}. A Transformer network is a sequential data processing network that does not use a form of \gls{RNN} in its architecture. It makes use of the attention principle, as discussed in chapter \ref{subsec:prednet}.  Also, Luo \cite{luo2018fast} proposes a real-time end-to-end 3D detection, tracking, and motion prediction network which only uses a \gls{CNN} and performs the prediction task within 30ms. They use a sequence of 3D \glspl{OGM} as input and perform 3D convolutions on it in the network to predict the motion of traffic participants. Both these methods achieve state-of-the-art results in state prediction. Future research could be done to investigate whether an adjusted version of these methods can be used for \gls{OGM} prediction.  
Furthermore, the methods that were evaluated in this review could hardly be compared due to the fact that most of the methods were trained on different datasets and evaluated using different metrics. In the future, to compare the methods better, they should trained on the same dataset and evaluated using the same metrics.  
